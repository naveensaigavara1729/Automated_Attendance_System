{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fafca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "img_size = 64\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('person_classifier_temp_100.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd697ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737a7323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N180015', 'N180027', 'N180082', 'N180086', 'N180121', 'N180160', 'N180255', 'N180309', 'N180310', 'N180390', 'N180473', 'N180518', 'N180520', 'N180530', 'N180548', 'N180550', 'N180606', 'N180616', 'N180636', 'N180638', 'N180676', 'N180678', 'N180681', 'N180696', 'N180726', 'N180727', 'N180742', 'N180749', 'N180798', 'N180814', 'N180827', 'N180872', 'N180884', 'N181128', 'N181150', 'N181164']\n"
     ]
    }
   ],
   "source": [
    "# specify the path of the directory\n",
    "directory_path = \"C:/Users/Naveen/Documents/Mproject/new/dataset/train/\"\n",
    "\n",
    "# create an empty list to store the directory names\n",
    "names = []\n",
    "\n",
    "# use the os.listdir() function to get a list of all directory names in the specified path\n",
    "for filename in os.listdir(directory_path):\n",
    "    # check if the filename is a directory\n",
    "    if os.path.isdir(os.path.join(directory_path, filename)):\n",
    "        # if it is a directory, append the name to the list\n",
    "        names.append(filename)\n",
    "\n",
    "# print the list of directory names\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "171c3221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "# Load the detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Load the predictor\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(\"face54.jpg\")\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces using HOG + Linear SVM detector\n",
    "faces = detector(gray, 1)\n",
    "\n",
    "# Create the \"faces\" directory if it doesn't exist\n",
    "if not os.path.exists(\"faces\"):\n",
    "    os.makedirs(\"faces\")\n",
    "\n",
    "# Loop through all files in the directory and remove them\n",
    "for filename in os.listdir(\"faces\"):\n",
    "    file_path = os.path.join(\"faces\", filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "\n",
    "# Iterate over each face\n",
    "for i, face in enumerate(faces):\n",
    "    # Get the landmarks/parts for the face in box d.\n",
    "    landmarks = predictor(gray, face)\n",
    "\n",
    "    # Extract face region as a numpy array\n",
    "    x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()\n",
    "    face_region = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Convert face region to grayscale\n",
    "    face_gray = cv2.cvtColor(face_region, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Save the face region as a grayscale image in the \"faces\" directory\n",
    "    cv2.imwrite(f\"faces/{i}.png\", face_gray)\n",
    "\n",
    "# Destroy all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5188aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "ID: 0   Person: N180681\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "ID: 1   Person: N180814\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "ID: 2   Person: N180749\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "ID: 3   Person: N180550\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "ID: 4   Person: N180473\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "ID: 5   Person: N180872\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "ID: 6   Person: N180390\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "ID: 7   Person: N180636\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "ID: 8   Person: N180616\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "ID: 9   Person: N180255\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "ID: 10   Person: N180530\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "ID: 11   Person: N180727\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "ID: 12   Person: N180827\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "ID: 13   Person: N180520\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "ID: 14   Person: N180310\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "ID: 15   Person: N180678\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "ID: 16   Person: N180606\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "ID: 17   Person: N180309\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "ID: 19   Person: N181128\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "ID: 20   Person: N180638\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "ID: 21   Person: N180676\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "ID: 22   Person: N180884\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "ID: 23   Person: N180086\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "ID: 24   Person: N180518\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "ID: 25   Person: N180082\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# dir_path = 'faces/'\n",
    "# c=0\n",
    "# for filename in os.listdir(\"faces\"):\n",
    "#     c+=1\n",
    "\n",
    "# for i in range(0,c):\n",
    "#     test_img = cv2.imread('faces/'+str(i)+'.png')\n",
    "#     test_img = cv2.resize(test_img, (img_size, img_size))\n",
    "#     test_img = np.array(test_img).reshape(-1, img_size, img_size, 3) / 255.0\n",
    "\n",
    "#     # Predict the person in the test image using the loaded model\n",
    "#     prediction = loaded_model.predict(test_img)\n",
    "#     person = names[np.argmax(prediction)]\n",
    "\n",
    "#     # Output the name of the person\n",
    "#     print(\"The person in the test image is:\",i,person)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "# from IPython.display import display, Image\n",
    "\n",
    "dir_path = 'faces/'\n",
    "c = 0\n",
    "for filename in os.listdir(\"faces\"):\n",
    "    c += 1\n",
    "\n",
    "# Create a set to store predicted persons\n",
    "predicted_persons = set()\n",
    "\n",
    "for i in range(c):\n",
    "    test_img = cv2.imread('faces/' + str(i) + '.png')\n",
    "    test_img = cv2.resize(test_img, (img_size, img_size))\n",
    "    test_img = np.array(test_img).reshape(-1, img_size, img_size, 3) / 255.0\n",
    "\n",
    "    # Predict the person in the test image using the loaded model\n",
    "    prediction = loaded_model.predict(test_img)\n",
    "    person = names[np.argmax(prediction)]\n",
    "\n",
    "    # Check if the person has already been predicted\n",
    "    if person not in predicted_persons:\n",
    "        # Add the predicted person to the set\n",
    "        predicted_persons.add(person)\n",
    "\n",
    "        # Output the name and ID of the person\n",
    "        print(\"ID:\", i, \"  Person:\", person)\n",
    "\n",
    "        # Display the image\n",
    "#         display(Image(filename='faces/' + str(i) + '.png'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39871da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
